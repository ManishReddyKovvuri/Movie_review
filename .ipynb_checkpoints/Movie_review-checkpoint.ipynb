{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO\n",
    "1. we have webscrape the \"metacrtics\"  website for top 500 movies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 : Webscraping\n",
    " 1.import required libaries \n",
    "    * requests : To retrived the Html of the source page\n",
    "    * bs4      : To converted the obtained html which in the form of text into soup object in which we can retrive specific                      data like headers, paragraphs, etc.\n",
    "    * lxml     : Helps bs4 to understand the html.\n",
    "    * csv      : To write or read into csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml\n",
    "import bs4\n",
    "import csv \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Loading the featured page links into a link to hit them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls =[\"https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc&page=0\",\n",
    "      \"https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc&page=1\",\n",
    "      \"https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc&page=2\",\n",
    "      \"https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc&page=3\",\n",
    "      \"https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc&page=4\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Initialise the varaible that are used to store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_short_href={} # used to store the href values \n",
    "\n",
    "movie_details={}    # Used to store the final movie details as \n",
    "                    #   { 'movie_name':{'Director':['director_name'], \n",
    "                    #                   'Principal Cast' : [name_1, name_2 ...name_m], \n",
    "                    #                    'Cast':['name_1, name_2... name_n'] }}  note m>n.\n",
    "            \n",
    "failed_items=[]     # Used to store the movie if of those movie where we have a failed attempt.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Below process is to achieve the link for each movies from the main page\n",
    "\n",
    "    result : now we have collection of end points of the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_num=0\n",
    "for url in urls:\n",
    "    result = requests.get(url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    soup = bs4.BeautifulSoup(result.text, \"lxml\")\n",
    "    div_tag = soup.find_all('div', class_=[\"browse_list_wrapper one browse-list-large\",\n",
    "                                           \"browse_list_wrapper two browse-list-large\",\n",
    "                                           \"browse_list_wrapper three browse-list-large\",\n",
    "                                           \"browse_list_wrapper four browse-list-large\"])\n",
    "    for item in div_tag:\n",
    "        for element in item.find_all('td', class_='clamp-image-wrap'):\n",
    "            index_num=index_num+1\n",
    "            source=element.find_all('a' , href= True)[0]\n",
    "            movie_short_href[index_num]=source['href'].replace('/movie/','')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. This is method is to scrape individual movie details from its respective website, if there is any kind of failure while scraping we store the the movie id  in a list (failed_items)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_data_from_website(i):\n",
    "    movie_link='https://www.metacritic.com/movie/'\n",
    "    url = movie_link+movie_short_href[i]+'/details'\n",
    "    result = requests.get(url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    if result.status_code != 200:\n",
    "        failed_items.append(i)\n",
    "    else:\n",
    "        soup = bs4.BeautifulSoup(result.text,'lxml')\n",
    "        tags = soup.find_all('table', class_='credits')\n",
    "        wanted_columns=['Director', 'Principal Cast', 'Cast']\n",
    "        movie_name = soup.find_all('div', class_='product_page_title oswald upper')[0].find_all('h1')[0].getText()\n",
    "        final_details={}\n",
    "        for table in tags:\n",
    "            column = table.find_all('th', class_=\"person\")[0].getText()\n",
    "            if column in wanted_columns:\n",
    "                details=[]\n",
    "                for name in table.find_all('a', href=True):\n",
    "                    details.append(name.getText().strip())\n",
    "                final_details[column]=details\n",
    "    if i in failed_items:\n",
    "        failed_items.remove(i)\n",
    "    movie_short_href[i] = movie_name\n",
    "    movie_details[movie_name] = final_details\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now we hit every movie link from our collection and check for any failed attempts, \n",
    "    if any there is any failed attempt, we now change their href value in the collection(movie_short_href)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in movie_short_href.keys():\n",
    "    retrive_data_from_website(i)\n",
    "\n",
    "if len(failed_items)>0:\n",
    "    for i in failed_items:\n",
    "        url = 'https://www.metacritic.com/movie/'+movie_short_href[i]\n",
    "        dummy = requests.get(url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        movie_short_href[i]=dummy.url[dummy.url.rindex('/')+1::]\n",
    "        retrive_data_from_website(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Write into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dict.csv\", \"w\", newline=\"\") as csv_file:  \n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in movie_details.items():\n",
    "        writer.writerow([key, value])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Read from a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict.csv') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    mydict = dict(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load the variable during dev phase \n",
    "\n",
    "Need to delete this when the project is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "1. Analyze how many times has each actor/actress appeared in these top 500 movies, analyze how many times has each director appeared in these top 500 movies, what can that tell you about their career?\n",
    " to do \n",
    "  First extract all cast into a list :\n",
    "  a) just the Principal cast?\n",
    "  b) Principal cast +  cast?\n",
    "  \n",
    "  Second make a register for cast with their count attached  \n",
    "  a) list of tuples  [(cast1,count),(cast2, count)...........]\n",
    "  b) dictionary {{cast1:count}, {cast2: count}......... }\n",
    "  c) just list  [cast1, cast2....][count1, count 2...] or [cast1, count1, cast2, count2..........]\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
