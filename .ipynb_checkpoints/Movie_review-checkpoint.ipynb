{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO\n",
    "2. Now save the scrapped data into CSV and Sql lite Db ( Db name : MovieInfoDatabase Table name: MovieInfoTable) \n",
    "   Take user input and show the movie details asked for like director of the movie or the cast of the movie from movie_details\n",
    "   varaible.\n",
    "   - Satya  \n",
    "   \n",
    "4. Now after sorting the count and rating for the cast and directo we should now give out analysis of their career.\n",
    "   - Satya\n",
    "    \n",
    "5. Find Cosine similarities between directors.\n",
    "   - Manish \n",
    "\n",
    "# Tasks completed\n",
    "1. Webscrapping of 500 movies and store them into dictionary\n",
    "   - Manish\n",
    "   \n",
    "3. Now make a count of cast and director based on that give review ( we only did the cast part there is also director part)\n",
    "     we store the cast & director data in varaibles : cast_details, director_details. \n",
    "   - Manish\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 : Webscraping\n",
    " 1.import required libaries \n",
    "    * requests : To retrived the Html of the source page\n",
    "    * bs4      : To converted the obtained html which in the form of text into soup object in which we can retrive specific                      data like headers, paragraphs, etc.\n",
    "    * lxml     : Helps bs4 to understand the html.\n",
    "    * csv      : To write or read into csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml\n",
    "import bs4\n",
    "import csv \n",
    "import time\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Loading the featured page links into a link to hit them and creating headers to mimic actual browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls =[\"https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc&page=0\",\n",
    "       \"https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc&page=1\",\n",
    "       \"https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc&page=2\",\n",
    "       \"https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc&page=3\",\n",
    "       \"https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc&page=4\"]\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Initialise the varaible that are used to store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_short_href={} # used to store the href values \n",
    "\n",
    "movie_details={}    # Used to store the final movie details as \n",
    "                    #   { 'movie_name':{'Director':['director_name'], \n",
    "                    #                   'Principal Cast' : [name_1, name_2 ...name_m], \n",
    "                    #                    'Cast':['name_1, name_2... name_n'] }}  note m>n.\n",
    "            \n",
    "failed_items=[]     # Used to store the movie if of those movie where we have a failed attempt.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Below process is to achieve the link for each movies from the main page\n",
    "\n",
    "    result : now we have collection of end points of the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_num=0\n",
    "for url in urls:\n",
    "    result = requests.get(url,headers=headers)\n",
    "    soup = bs4.BeautifulSoup(result.text, \"lxml\")\n",
    "    div_tag = soup.find_all('div', class_=[\"browse_list_wrapper one browse-list-large\",\n",
    "                                           \"browse_list_wrapper two browse-list-large\",\n",
    "                                           \"browse_list_wrapper three browse-list-large\",\n",
    "                                           \"browse_list_wrapper four browse-list-large\"])\n",
    "    for item in div_tag:\n",
    "        for element in item.find_all('td', class_='clamp-image-wrap'):\n",
    "            index_num=index_num+1\n",
    "            source=element.find_all('a' , href= True)[0]\n",
    "            movie_short_href[index_num]=source['href'].replace('/movie/','')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. This is method is to scrape individual movie details from its respective website, if there is any kind of failure while scraping we store the the movie id  in a list (failed_items)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrive_data_from_website(i):\n",
    "    movie_link='https://www.metacritic.com/movie/'\n",
    "    url = movie_link+movie_short_href[i]+'/details'\n",
    "    result = requests.get(url,headers=headers)\n",
    "    if result.status_code != 200:\n",
    "        failed_items.append(i)\n",
    "    else:\n",
    "        \n",
    "        final_details={}\n",
    "        soup = bs4.BeautifulSoup(result.text,'lxml')\n",
    "        tags = soup.find_all('table', class_='credits')\n",
    "        wanted_columns=['Director', 'Principal Cast', 'Cast']\n",
    "        movie_name = soup.find_all('div', class_='product_page_title oswald upper')[0].find_all('h1')[0].getText()\n",
    "        meta_score = soup.find_all('a', class_ = 'metascore_anchor')[0].getText().strip()\n",
    "        final_details['meta_score']=meta_score\n",
    "        for table in tags:\n",
    "            column = table.find_all('th', class_=\"person\")[0].getText()\n",
    "            if column in wanted_columns:\n",
    "                details=[]\n",
    "                for name in table.find_all('a', href=True):\n",
    "                    details.append(name.getText().strip())\n",
    "                final_details[column]=details\n",
    "        if movie_name not in movie_short_href.values():\n",
    "            movie_short_href[i] = movie_name\n",
    "        movie_details[movie_short_href[i]] = final_details\n",
    "    if i in [100,200,300,400,500]:\n",
    "        time.sleep(2)\n",
    "    if i in failed_items:\n",
    "        failed_items.remove(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now we hit every movie link from our collection and check for any failed attempts,\n",
    "    if any there is any failed attempt, that implies that the href we obtained has different value which the website has\n",
    "    internally rerouted, so just for the failed items instead of hitting the details  page we go step bye step and find the\n",
    "    actual href value \n",
    "    \n",
    "    example:\n",
    "    movie href value = 'citizen-kane' in page - 1\n",
    "    we would be hitting = '/movies/citizen-kane/details' which is wrong endpoint.\n",
    "    actual endpoint = '/movies/citizen-kane-1941/details' \n",
    "    \n",
    "   for movies like these which are less than 10 in count,\n",
    "    we first hit the movie page which is '/movies/citizen-kane'  which would internal redirect at the server side into\n",
    "   'movie/citizen-kane-1941' we now take the url and update the href value in movie_short_href variable and continue the \n",
    "    process\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in movie_short_href.keys():\n",
    "    retrive_data_from_website(i)\n",
    "if len(failed_items)>0:\n",
    "    for i in failed_items:\n",
    "        url = 'https://www.metacritic.com/movie/'+movie_short_href[i]\n",
    "        dummy = requests.get(url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        movie_short_href[i]=dummy.url[dummy.url.rindex('/')+1::]\n",
    "        retrive_data_from_website(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Store into CSV and Sql lite Db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dict.csv\", \"w\", newline=\"\") as csv_file:  \n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in movie_details.items():\n",
    "        writer.writerow([key, value])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Read from a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict.csv') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    mydict = dict(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load the variable during dev phase \n",
    "\n",
    "Need to delete this when the project is completed. copy the cell from variable_pro.ipynb and run it under so we can load movie_details and movie_short_href"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "1. Analyze how many times has each actor/actress appeared in these top 500 movies, analyze how many times has each director appeared in these top 500 movies, what can that tell you about their career?\n",
    " to do \n",
    "  First extract all cast into a list :\n",
    "  a) just the Principal cast?\n",
    "  b) Principal cast +  cast?\n",
    "  \n",
    "  Second make a register for cast with their count attached  \n",
    "  a) list of tuples  [(cast1,count),(cast2, count)...........]\n",
    "  b) dictionary {{cast1:count}, {cast2: count}......... }\n",
    "  c) just list  [cast1, cast2....][count1, count 2...] or [cast1, count1, cast2, count2..........]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3:List the names of the cast  and director that have appeared in different movies\n",
    "1. Filter all the cast  and directors from each movie and append them to the list.\n",
    "    cast_details={'name' :{count:'v',\n",
    "                          rating:'v'}}\n",
    "    director_details = {'name' :{count:'v',\n",
    "                          rating:'v'}}\n",
    "                          \n",
    "     Count is the number of movies that they worked in.\n",
    "     Rating would be the average of the rating of the all the movies that they worked in.\n",
    "                               \n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_details={}\n",
    "director_details={}\n",
    "def add_castnames_count(cast_names,score):\n",
    "    for name in cast_names:\n",
    "        cast_details[name]= cast_details.get(name,{'count':0, 'rating': 0})\n",
    "        cast_details[name]['count'] = cast_details[name].get('count',1) + 1\n",
    "        cast_details[name]['rating'] = cast_details[name]['rating']+int(score)\n",
    "\n",
    "            \n",
    "def add_directornames_count(director_name,score):\n",
    "    for name in director_name:\n",
    "        director_details[name]= director_details.get(name,{'count':0, 'rating': 0})\n",
    "        director_details[name]['count'] = director_details[name].get('count',1) + 1\n",
    "        director_details[name]['rating'] = director_details[name]['rating']+int(score)     \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie_name,movies in movie_details.items():\n",
    "    if 'Principal Cast' in movies.keys():\n",
    "        add_castnames_count(movies['Principal Cast'], movies['meta-score'])\n",
    "    if 'Cast' in movies.keys():\n",
    "        add_castnames_count(movies['Cast'],movies['meta-score'])\n",
    "    if 'Director' in movies.keys():\n",
    "        add_directornames_count(movies['Director'],movies['meta-score'])\n",
    "for name in cast_details.keys():\n",
    "        cast_details[name]['rating'] = cast_details[name]['rating']/cast_details[name]['count']\n",
    "for name in director_details.keys():\n",
    "        director_details[name]['rating'] = director_details[name]['rating']/director_details[name]['count']\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6492"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(cast_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "410"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(director_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Task4 : Finding cosine similarities between  Directors\n",
    "\n",
    "There are 410  distinct Director in the top 500 movies now we will have to find the most similar pair of director.\n",
    "\n",
    "First we create a collection of  directors along with the cast they worked with and how many time that they have worked.\n",
    "\n",
    "{'director-1':{'cast-1' : 1, 'cast-2' : 3, ...}..}\n",
    "\n",
    " \n",
    " now for finding cosine similarity between two director we need find the all the cast which worked with director-1 and director-2, and then created a vector which consits of the number of time that they worked with the cast.\n",
    " \n",
    " suppose we take a pair of director as director-1, director-2 and lets look at the vector that we need to generate.\n",
    " \n",
    " Example:\n",
    " \n",
    " 'director-1':{'cast-1' : 1, \n",
    "                'cast-2' : 2, }\n",
    " 'director-2':{'cast-3' : 3, \n",
    "               'cast-2' : 4, }\n",
    "               \n",
    "  So the length of the vector is going to be the distinct cast of both directors.\n",
    "  [cast-1, cast-2. cast-3]\n",
    "  \n",
    "  the director vectors are going to be \n",
    "  director-1= [1, 2, 0 ]\n",
    "  \n",
    "  director-2 = [0, 4, 3]\n",
    "  \n",
    "  now we give this input to our cosine function and get the similarity.\n",
    "\n",
    "  \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_cast_details={}\n",
    "\n",
    "for v in movie_details.values():\n",
    "    for director_name in v['Director']:\n",
    "        cast_data=director_cast_details.get(director_name,{})\n",
    "        cast = v.get('Principal Cast',[])+(v.get('Cast',[]))\n",
    "        for name in cast:\n",
    "            cast_data[name] = cast_data.get(name,0)+1\n",
    "        director_cast_details[director_name]=cast_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "same\n",
      "same\n"
     ]
    }
   ],
   "source": [
    "def inner_product(vector_1, vector_2):\n",
    "    product_sum = 0\n",
    "    for i in range(len(vector_1)):\n",
    "        product_sum = product_sum +(vector_1[i]*vector_2[i])\n",
    "    return product_sum\n",
    "        \n",
    "    \n",
    "def cosine_similarity(director_1, director_2):\n",
    "    common_cast= set(list(director_1.keys())+list(director_2.keys()))\n",
    "    vector_1=[director_1.get(i,0) for i in common_cast]\n",
    "    vector_2=[director_2.get(i,0) for i in common_cast]\n",
    "    numerator = inner_product(vector_1,vector_2)\n",
    "    if numerator==0:\n",
    "        return 0\n",
    "    denominator = sqrt(inner_product(vector_1,vector_1)) * sqrt(inner_product(vector_2,vector_2))\n",
    "    if denominator==0:\n",
    "        return 0\n",
    "    return numerator/denominator\n",
    "\n",
    "\n",
    "# print(cosine_similarity(director_cast_details['Alfred Hitchcock'],director_cast_details['Francis Ford Coppola']))\n",
    "max_similarity={'value':0,'pair':[]}\n",
    "\n",
    "for name in ['a','b']:#director_cast_details.keys():\n",
    "    mincos=0\n",
    "    for name2 in ['a','b']:#director_cast_details.keys():\n",
    "        if name==name2:\n",
    "            print('same')\n",
    "            continue\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
